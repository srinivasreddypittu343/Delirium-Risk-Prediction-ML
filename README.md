# ğŸ§  Delirium Risk Prediction using Classical Machine Learning

Predicting which older surgical patients are at risk of **post-operative delirium** using
routine clinical data and classical ML models.

> **Goal:** turn everyday hospital data (age, frailty, labs, ICU info) into a  
> simple **Low vs High delirium risk** flag that could support clinicians.

---

## 1. Project Overview

Post-operative delirium is an acute confusion state that often affects older adults after
surgery. It is strongly associated with longer length of stay, falls, complications, and
higher mortality â€“ but some cases are preventable if high-risk patients are identified
early.

In this project I:

- Cleaned and preprocessed an anonymised delirium dataset (`delirium_ml.xlsx`)
- Trained and compared several **classical ML models**:
  - Logistic Regression  
  - Random Forest  
  - SVM (RBF kernel)  
  - Multi-Layer Perceptron (MLP)
- Explored patient phenotypes using **PCA + K-Means clustering**
- Built a **patient-level interface** that turns model output into an intuitive  
  **Low vs High risk** interpretation.

This repository is meant for learning and demonstration purposes in a **masterâ€™s-level
machine learning course**, not for clinical use.

---

## 2. Repository Structure

```text
.
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ data/
â”‚   â””â”€â”€ delirium_ml_sample.xlsx      # small sample of the original dataset
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Delirium_Prediction.ipynb    # full exploratory notebook
â””â”€â”€ src/
    â””â”€â”€ delirium_pipeline.py         # clean, runnable script
```

ğŸ“Š 3. Dataset

The project uses an anonymised delirium dataset of elderly surgical / hip-fracture patients.

Each row = one patient
Each column = a clinical feature

Main columns:

ğŸ§â€â™‚ï¸ Demographics

Age, Height, BMI

ğŸ’ª Frailty

Frailty Index

ğŸ§ª Laboratory values

Hct (haematocrit)

Alb (albumin)

Cre (creatinine)

(plus other routine labs)

ğŸ¥ Peri-operative data

DuraAnes â€“ duration of anaesthesia

DuraSurg â€“ duration of surgery

ICU â€“ ICU admission (0/1)

Infusion, FFP, Vasopressor, Postop LOS, etc.

ğŸ¯ Target label

Postop Delirium â†’ 0 = no, 1 = yes

Delirium is the minority class â†’ imbalanced classification

For sharing in this repo, data/delirium_ml_sample.xlsx contains a small, de-identified subset with the same schema.
If you have permission, you can swap in the full dataset locally.

ğŸ›  4. Methods
4.1 Pre-processing pipeline

Key steps before modelling:

ğŸ”¢ Convert text-encoded numeric columns (e.g. LOS, Hct, Alb, Cre) â†’ proper numeric

ğŸ•³ Handle missing values with median imputation

ğŸ†” Drop any ID columns (SN, ID, etc.) to avoid leakage

ğŸ“¦ Define:

X â€“ all feature columns

y â€“ Postop Delirium

âœ‚ï¸ Split data with stratified 80/20 trainâ€“test split

ğŸ“ Apply StandardScaler for models that require scaling (LR, SVM, MLP)

4.2 Models (all in scikit-learn)

Logistic Regression

Linear baseline, interpretable coefficients

Uses class_weight="balanced" to handle class imbalance

Random Forest

Ensemble of decision trees

Captures non-linear interactions

Provides feature importances (used for key risk factors and interface)

SVM (RBF kernel)

Margin-based classifier with a non-linear RBF kernel

Trained on scaled features

MLP Neural Network

Small feed-forward network (2 hidden layers, ReLU, early stopping)

Learns more complex non-linear relations

4.3 Evaluation metrics

â­ Primary metric: ROC AUC on the test set

ğŸ“‰ Also report: precision, recall, F1-score, confusion matrix

ğŸ©º Clinical focus: recall for delirium = 1
â†’ missing high-risk patients is more serious than a few extra false positives

Approximate test ROC AUC:

Model	ROC AUC (test)
Logistic Regression	~0.78
Random Forest	~0.60
SVM (RBF)	~0.69
MLP Neural Network	~0.80 (best)
ğŸ” 5. Unsupervised Analysis â€“ PCA & Clustering

To understand the structure of the patient cohort, the project also uses unsupervised methods:

5.1 PCA (Principal Component Analysis)

Apply PCA to the scaled features

PC1 explains â‰ˆ 14.2% of variance

PC2 explains â‰ˆ 8.6% of variance

Together â‰ˆ 23% of total variance

Plot patients in PC1â€“PC2 space, coloured by delirium outcome
â†’ certain regions contain more delirium cases â†’ potential high-risk zones

5.2 K-Means clustering (k = 3)

Run K-Means (k = 3) in the PCA space

Clusters (approximate values):

Cluster sizes: 109, 30, 57 patients

Delirium rates: 6.4%, 33.3%, 12.3%

Interpretation:

One cluster clearly has a much higher delirium rate

Acts as a high-risk phenotype â€“ a subgroup of patients who are significantly more likely to develop delirium

This unsupervised view supports the supervised models by showing that high-risk groups emerge naturally from the data.

ğŸ§‘â€âš•ï¸ 6. Patient-Level Risk Interface

The repository also contains a small patient-level interface built around the trained Random Forest.

6.1 How it works

Build a template patient using the median value of each feature from the training data.

Accept a Python dict of overrides (e.g. Age, Frailty Index, ICU, Hct, Alb, Cre).

Construct a one-row DataFrame in the same column order as training.

Use the Random Forest to predict:

class label (0 / 1)

probability of delirium (0â€“1)

Convert the probability into a simple interpretation:

p < 0.5 â†’ â€œLOW chance of post-operative deliriumâ€

p â‰¥ 0.5 â†’ â€œHIGH risk â€“ consider closer monitoringâ€

6.2 Why itâ€™s useful

Hides model complexity behind a single, intuitive output

Uses variables that are already present in hospital systems (age, frailty, labs, ICU)

Easy to extend into:

a Streamlit app

or an EHR-integrated risk widget in future work

This interface shows how a research model can be turned into something that is clinician-friendly and actionable, while still being fully transparent in the code.
---

